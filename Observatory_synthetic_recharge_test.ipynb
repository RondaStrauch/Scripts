{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Watershed Dynamics Model \n",
    "\n",
    "<img src=\"https://www.washington.edu/brand/files/2014/09/W-Logo_Purple_Hex.png\" style=\"float:right;width:300px;padding:20px\">   \n",
    "\n",
    "Explore recharge and landsliding in the North Cascades National Park from a HydroShare Observatory. <br />\n",
    "<br />\n",
    "This Jupyter Notebook contains selected model components <br /> \n",
    "of the Watershed Dynamics model identified with a bullet  <br /> \n",
    "<br /> \n",
    "Download daily 1/16 degree gridded meteorology data, <br /> \n",
    "Download daily 1/16 degree VIC fluxes.<br /> \n",
    "Save data to a new HydroShare resource, <br /> \n",
    "Disaggreate daily data to 3-hourly, <br /> \n",
    "Estimate radiation and relative humidity from climate data with MetSim, <br /> \n",
    "Visualize daily, monthly, and annual climate data. <br /> \n",
    "* Test Recharge option in Landlab LandslideProbability component<br /> \n",
    "* Run Landlab LandslideProbability <br /> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HydroShare Setup and Preparation\n",
    "\n",
    "To run this notebook, we must import several libaries.\n",
    "The hs_utils library provides functions for interacting with HydroShare, including resource querying, dowloading and creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utilities import hydroshare #, observatory_localimport_timeseries\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# set variables for interacting with HydroShare from this notebook\n",
    "hs=hydroshare.hydroshare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is temporary until the .py is uploaded to HydroShare and Landlab utilities\n",
    "# create source paths for the observatory scripts\n",
    "Dest_dir = '/'.join(['/home/jovyan/work/notebooks','data',os.environ['HS_RES_ID'],os.environ['HS_RES_ID'],'data','contents'])\n",
    "obs_sx_srcs = ['/'.join([Dest_dir, paths]) for paths in os.listdir(Dest_dir) if paths.startswith('landlab_') and paths.endswith('.py')]\n",
    "\n",
    "# create the destination directory\n",
    "obs_sx_dest = '/'.join(['/home/jovyan/work/notebooks','utilities'])\n",
    "\n",
    "# copy the observatory scripts into the utilities folder\n",
    "for eachsrc in obs_sx_srcs:\n",
    "    shutil.copy(eachsrc, obs_sx_dest)\n",
    "    print(eachsrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from utilities import landlab_landslide\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from landlab import RasterModelGrid\n",
    "from landlab.components.landslides import LandslideProbability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to establish a secure connection with HydroShare. This is done by simply instantiating the hydroshare class that is defined within hs_utils. In addition to connecting with HydroShare, this command also sets and prints environment variables for several parameters that will be useful for saving your work back to HydroShare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create object to map the home directory\n",
    "homedir = Dest_dir + '/'\n",
    "print homedir\n",
    "\n",
    "# if the working directory is not starting at homedir, set it to homedir\n",
    "if os.getcwd() != homedir:\n",
    "    os.chdir(homedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious about where the data is being downloaded, click on the Jupyter Notebook dashboard icon to return to the File System view.  The homedir directory location printed above is where you can find the data and contents you will download to a HydroShare JupyterHub server.  At the end of this work session, you can migrate this data to the HydroShare iRods server as a Generic Resource. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a grid on which to calculate landslide probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Instatiate a synthetic model domain\n",
    "grid = RasterModelGrid((5, 4), spacing=(0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add required fields for the landslide component.\n",
    "gridnodes = grid.number_of_nodes\n",
    "grid['node']['topographic__slope'] = np.random.rand(gridnodes)\n",
    "scatter_dat = np.random.randint(1, 10, gridnodes)\n",
    "grid['node']['topographic__specific_contributing_area']= \\\n",
    "         np.sort(np.random.randint(30, 900, gridnodes))\n",
    "grid['node']['soil__transmissivity']= \\\n",
    "         np.sort(np.random.randint(5, 20, gridnodes),-1)\n",
    "grid['node']['soil__mode_total_cohesion']= \\\n",
    "         np.sort(np.random.randint(30, 900, gridnodes))\n",
    "grid['node']['soil__minimum_total_cohesion']= \\\n",
    "         grid.at_node['soil__mode_total_cohesion'] - scatter_dat\n",
    "grid['node']['soil__maximum_total_cohesion']= \\\n",
    "         grid.at_node['soil__mode_total_cohesion'] + scatter_dat\n",
    "grid['node']['soil__internal_friction_angle']= \\\n",
    "         np.sort(np.random.randint(26, 40, gridnodes))\n",
    "grid['node']['soil__thickness']= \\\n",
    "         np.sort(np.random.randint(1, 10, gridnodes))\n",
    "grid['node']['soil__density']= \\\n",
    "         2000. * np.ones(grid.number_of_nodes)\n",
    "         \n",
    "grid_size = grid.number_of_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of iterations to run Monte Carlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Recharge Option - uniform distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Option 1 - uniform distribution\n",
    "distribution1 = 'uniform'\n",
    "Remin_value = 20.\n",
    "Remax_value = 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recharge Option - Lognormal-Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distribution2 = 'lognormal_uniform'\n",
    "Remean = 4.\n",
    "Restandard_deviation = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recharge Option - Lognormal - Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distribution3 = 'lognormal_spatial'\n",
    "Remean3 = np.random.randint(2,7,grid_size)\n",
    "Restandard_deviation3 = np.random.rand(grid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recharge Option - Data driven - Spatial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HSD_dict = {}\n",
    "HSD_id_dict = {}\n",
    "fract_dict = {}\n",
    "# HSD id and recharge array\n",
    "for vkey in range(2,8):\n",
    "    HSD_dict[vkey] = np.random.randint(20,120,10)\n",
    "# node id and HSD grid ids\n",
    "for ckey in grid.core_nodes:\n",
    "    HSD_id_dict[ckey] = np.random.randint(2,8,2)\n",
    "# node id and HSD grid fraction\n",
    "for ckey in grid.core_nodes:\n",
    "    fract_dict[ckey] =  np.random.rand(2)\n",
    "distribution4 = 'fully_distributed'\n",
    "#HSD ('hydrology source domain') dictionaries\n",
    "HSD_inputs = [HSD_dict,HSD_id_dict, fract_dict]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and compare the Component from four Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LS_prob1 = LandslideProbability(grid,number_of_iterations=n,\n",
    "    groudwater__recharge_distribution=distribution1,\n",
    "    groundwater__recharge_min_value=Remin_value,\n",
    "    groundwater__recharge_max_value=Remax_value)\n",
    "LS_prob1.calculate_landslide_probability()\n",
    "#lognormal_uniform\n",
    "LS_prob2 = LandslideProbability(grid,number_of_iterations=n,\n",
    "    groudwater__recharge_distribution=distribution2,\n",
    "    groundwater__recharge_mean=Remean,\n",
    "    groundwater__recharge_standard_deviation=Restandard_deviation)\n",
    "LS_prob2.calculate_landslide_probability()\n",
    "#lognormal_spatial\n",
    "LS_prob3 = LandslideProbability(grid,number_of_iterations=n,\n",
    "    groudwater__recharge_distribution=distribution3,\n",
    "    groundwater__recharge_mean=Remean3,\n",
    "    groundwater__recharge_standard_deviation=Restandard_deviation3)\n",
    "LS_prob3.calculate_landslide_probability()\n",
    "#HSD\n",
    "LS_prob4 = LandslideProbability(grid,number_of_iterations=n,\n",
    "    groudwater__recharge_distribution=distribution4,\n",
    "    groudwater__recharge_HSD_inputs=HSD_inputs)\n",
    "LS_prob4.calculate_landslide_probability()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
