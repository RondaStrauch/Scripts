{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Watershed Dynamics Model \n",
    "\n",
    "<img src=\"https://www.washington.edu/brand/files/2014/09/W-Logo_Purple_Hex.png\" style=\"float:right;width:300px;padding:20px\">   \n",
    "\n",
    "Explore recharge and landsliding in the North Cascades National Park from a HydroShare Observatory. <br />\n",
    "<br />\n",
    "This Jupyter Notebook runs the landslide component on a synthetic<br /> \n",
    "Landlab grid using four recharge options.<br />\n",
    "<br /> \n",
    "* Setup synthetic grid and generate data<br />\n",
    "* Parameterize recharge options<br /> \n",
    "* Run LandslideProbability function from Landlab landslide component<br /> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HydroShare Setup and Preparation\n",
    "\n",
    "To run this notebook, we must import several libaries.\n",
    "The hs_utils library provides functions for interacting with HydroShare, including resource querying, dowloading and creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the following system variables:\n",
      "   HS_USR_NAME = RStrauch\n",
      "   HS_RES_ID = 0f4efd1cedb64a5a9fa90cf1f248e22f\n",
      "   HS_RES_TYPE = genericresource\n",
      "   JUPYTER_HUB_IP = hydroroger.ncsa.illinois.edu\n",
      "\n",
      "These can be accessed using the following command: \n",
      "   os.environ[key]\n",
      "\n",
      "   (e.g.)\n",
      "   os.environ[\"HS_USR_NAME\"]  => RStrauch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:green;\">Successfully established a connection with HydroShare</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from utilities import hydroshare #, observatory_localimport_timeseries\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# set variables for interacting with HydroShare from this notebook\n",
    "hs=hydroshare.hydroshare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import landlab_landslide\n",
    "from landlab_landslide import LandslideProbability  #customized landlab landslide component updating ver1 in Landlab\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from landlab import RasterModelGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious about where the data is being downloaded, click on the Jupyter Notebook dashboard icon to return to the File System view.  The homedir directory location printed above is where you can find the data and contents you will download to a HydroShare JupyterHub server.  At the end of this work session, you can migrate this data to the HydroShare iRods server as a Generic Resource. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a grid on which to calculate landslide probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Instatiate a synthetic model domain\n",
    "grid = RasterModelGrid((5, 4), spacing=(0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add required fields for the landslide component.\n",
    "gridnodes = grid.number_of_nodes\n",
    "grid['node']['topographic__slope'] = np.random.rand(gridnodes)\n",
    "scatter_dat = np.random.randint(1, 10, gridnodes)\n",
    "grid['node']['topographic__specific_contributing_area']= \\\n",
    "         np.sort(np.random.randint(30, 900, gridnodes))\n",
    "grid['node']['soil__transmissivity']= \\\n",
    "         np.sort(np.random.randint(5, 20, gridnodes),-1)\n",
    "grid['node']['soil__mode_total_cohesion']= \\\n",
    "         np.sort(np.random.randint(30, 900, gridnodes))\n",
    "grid['node']['soil__minimum_total_cohesion']= \\\n",
    "         grid.at_node['soil__mode_total_cohesion'] - scatter_dat\n",
    "grid['node']['soil__maximum_total_cohesion']= \\\n",
    "         grid.at_node['soil__mode_total_cohesion'] + scatter_dat\n",
    "grid['node']['soil__internal_friction_angle']= \\\n",
    "         np.sort(np.random.randint(26, 40, gridnodes))\n",
    "grid['node']['soil__thickness']= \\\n",
    "         np.sort(np.random.randint(1, 10, gridnodes))\n",
    "grid['node']['soil__density']= \\\n",
    "         2000. * np.ones(grid.number_of_nodes)\n",
    "         \n",
    "grid_size = grid.number_of_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of iterations to run Monte Carlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Recharge Option - uniform distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribution1 = 'uniform'\n",
    "Remin_value = 20.\n",
    "Remax_value = 120.\n",
    "LS_prob1 = LandslideProbability(grid,number_of_iterations=n,\n",
    "    groudwater__recharge_distribution=distribution1,\n",
    "    groundwater__recharge_min_value=Remin_value,\n",
    "    groundwater__recharge_max_value=Remax_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recharge Option - Lognormal-Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distribution2 = 'lognormal_uniform'\n",
    "Remean = 4.\n",
    "Restandard_deviation = 0.25\n",
    "LS_prob2 = LandslideProbability(grid,number_of_iterations=n,\n",
    "    groudwater__recharge_distribution=distribution2,\n",
    "    groundwater__recharge_mean=Remean,\n",
    "    groundwater__recharge_standard_deviation=Restandard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recharge Option - Lognormal - Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distribution3 = 'lognormal_spatial'\n",
    "Remean3 = np.random.randint(2,7,grid_size)\n",
    "Restandard_deviation3 = np.random.rand(grid_size)\n",
    "LS_prob3 = LandslideProbability(grid,number_of_iterations=n,\n",
    "    groudwater__recharge_distribution=distribution3,\n",
    "    groundwater__recharge_mean=Remean3,\n",
    "    groundwater__recharge_standard_deviation=Restandard_deviation3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recharge Option - Data driven - Spatial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HSD_dict = {}\n",
    "HSD_id_dict = {}\n",
    "fract_dict = {}\n",
    "# HSD id and recharge array\n",
    "for vkey in range(2,8):\n",
    "    HSD_dict[vkey] = np.random.randint(20,120,10)\n",
    "# node id and HSD grid ids\n",
    "for ckey in grid.core_nodes:\n",
    "    HSD_id_dict[ckey] = np.random.randint(2,8,2)\n",
    "# node id and HSD grid fraction\n",
    "for ckey in grid.core_nodes:\n",
    "    fract_dict[ckey] =  np.random.rand(2)\n",
    "distribution4 = 'fully_distributed'\n",
    "#HSD ('hydrology source domain') dictionaries\n",
    "HSD_inputs = [HSD_dict,HSD_id_dict, fract_dict]\n",
    "\n",
    "LS_prob4 = LandslideProbability(grid,number_of_iterations=n,\n",
    "    groudwater__recharge_distribution=distribution4,\n",
    "    groudwater__recharge_HSD_inputs=HSD_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and compare the Landslide Component sensitivity based on four recharge options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "LS_prob1.calculate_landslide_probability()\n",
    "\n",
    "LS_prob2.calculate_landslide_probability()\n",
    "\n",
    "LS_prob3.calculate_landslide_probability()\n",
    "\n",
    "LS_prob4.calculate_landslide_probability()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.number_of_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3832839 ,  0.40095853,  0.5536129 ,  0.43240317,  0.4274691 ,\n",
       "        0.41036259,  0.42995855,  0.437291  ,  0.44057258,  0.4551912 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LS_prob4.landslide__factor_of_safety_histogram[core_nodes[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "core_nodes = LS_prob1.grid.core_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  6,  9, 10, 13, 14])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.core_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
